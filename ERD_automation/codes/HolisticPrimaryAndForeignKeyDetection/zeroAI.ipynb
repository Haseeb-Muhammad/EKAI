{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e218eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "# import hyperloglog\n",
    "from datasketch import HyperLogLog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86f4281",
   "metadata": {},
   "source": [
    "# Points\n",
    "For now i am assuming that primary key is only a single attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905e9723",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attribute:\n",
    "    def __init__(self, table_name, attribute_name, values):\n",
    "        self.table_name = table_name\n",
    "        self.attribute_name = attribute_name\n",
    "        self.values = values\n",
    "\n",
    "        self.uniquness = self.estUniqueness()\n",
    "        self.cardinality=1\n",
    "        self.value_length = 1/max(1, max([len(x) for x in values]) - 8)\n",
    "        self.position = 0\n",
    "        self.suffix = self.check_suffix()\n",
    "        \n",
    "        self.dependent = [] # It's dependent attributes\n",
    "        self.reference = [] # Attributes that it references from \n",
    "\n",
    "    def estUniqueness(self):\n",
    "        hll = HyperLogLog()\n",
    "        total = 0\n",
    "        \n",
    "        for value in self.values:\n",
    "            hll.update(str(value).encode('utf8'))\n",
    "            total +=1\n",
    "        # print(f\"{hll.count()=}\")\n",
    "        \n",
    "        return hll.count() / total\n",
    "    \n",
    "    def check_suffix(self, suffix_list=[\"key\", 'id', 'nr', 'no']):\n",
    "        for suffix in suffix_list:\n",
    "            if suffix in self.attribute_name:\n",
    "                return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "730b5f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 \n",
      " CSV files: ['event.csv', 'pet.csv']\n",
      "Processing event.csv: 10 rows, 4 columns\n",
      "Added attribute: event.name Total Values: 10\n",
      "1.0\n",
      "Added attribute: event.date Total Values: 10\n",
      "0.5\n",
      "Added attribute: event.type Total Values: 10\n",
      "0.3333333333333333\n",
      "Added attribute: event.remark  Total Values: 8\n",
      "0.25\n",
      "Processing pet.csv: 8 rows, 6 columns\n",
      "Added attribute: pet.lexicon Total Values: 8\n",
      "1.0\n",
      "Added attribute: pet.owner Total Values: 8\n",
      "0.5\n",
      "Added attribute: pet.species Total Values: 8\n",
      "0.3333333333333333\n",
      "Added attribute: pet.sex Total Values: 8\n",
      "0.25\n",
      "Added attribute: pet.birth Total Values: 8\n",
      "0.2\n",
      "Added attribute: pet.death Total Values: 8\n",
      "0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "def load_csv_files(directory_path):\n",
    "    attributes = {}\n",
    "\n",
    "    csv_files = [f for f in os.listdir(directory_path)]\n",
    "\n",
    "    print(f\"Found {len(csv_files)} \\n CSV files: {csv_files}\")    \n",
    "\n",
    "    for filename in csv_files:\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        table_name = os.path.splitext(filename)[0]\n",
    "\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df\n",
    "        print(f\"Processing {filename}: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "\n",
    "        for i, column in enumerate(df.columns):\n",
    "            non_null_values = df[column].dropna().tolist()\n",
    "            if non_null_values:\n",
    "                attr = Attribute(table_name, column, non_null_values)\n",
    "                attr.position = 1/(i+1)\n",
    "                attributes[f\"{table_name}.{column}\"] = attr\n",
    "                print(f\"Added attribute: {attr.table_name}.{attr.attribute_name} Total Values: {len(attr.values)}\")\n",
    "                print(attr.position)\n",
    "\n",
    "    return attributes\n",
    "    \n",
    "attributes = load_csv_files(\"/home/haseeb/Desktop/EKAI/ERD_automation/Dataset/train/menagerie-db\")            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72a2895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event.name=pet.lexicon\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def read_IND(file_path):\n",
    "    '''\n",
    "        fills up the dependent and reference array of attributes\n",
    "    '''\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            vars = line.strip().split(\"=\")\n",
    "            attributes[vars[0]].references = attributes[vars[1]]\n",
    "            attributes[vars[1]].dependent = attributes[vars[0]]\n",
    "read_IND(\"/home/haseeb/Desktop/EKAI/ERD_automation/codes/inclusionDependencyWithSpider/spider_results/menagerie-db.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72e8595b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.8127666768532549)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes[\"event.name\"].uniquness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c455553",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ERD_automation_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
