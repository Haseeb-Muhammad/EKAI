{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e218eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datasketch import HyperLogLog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86f4281",
   "metadata": {},
   "source": [
    "# Points\n",
    "For now i am assuming that primary key is only a single attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a65f6869",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IND:\n",
    "    \"\"\"\n",
    "    A class representing Inclusion Dependencies between attributes.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dependent : Attribute\n",
    "        The dependent attribute in the inclusion dependency\n",
    "    reference : Attribute\n",
    "        The reference attribute in the inclusion dependency\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dependent, reference):\n",
    "        self.dependent = dependent\n",
    "        self.reference = reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "905e9723",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attribute:\n",
    "    \"\"\"\n",
    "    A class representing a database table attribute with metadata for primary key detection.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    table_name : str\n",
    "        Name of the database table\n",
    "    attribute_name : str\n",
    "        Name of the attribute/column\n",
    "    values : list\n",
    "        List of values in the attribute\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    fullName : str\n",
    "        Fully qualified name (table_name.attribute_name)\n",
    "    uniquness : float\n",
    "        Estimated uniqueness score using HyperLogLog\n",
    "    cardinality : int\n",
    "        Cardinality score (default 1)\n",
    "    value_length : float\n",
    "        Score based on value lengths\n",
    "    position : float \n",
    "        Score based on column position \n",
    "    suffix : int\n",
    "        Score based on common primary key suffixes\n",
    "    pkScore : float\n",
    "        Combined score for primary key likelihood\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    estUniqueness()\n",
    "        Estimates uniqueness of values using HyperLogLog\n",
    "    check_suffix(suffix_list)\n",
    "        Checks if attribute name contains common primary key suffixes\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, table_name, attribute_name, values):\n",
    "        self.table_name = table_name\n",
    "        self.attribute_name = attribute_name\n",
    "        self.values = values\n",
    "        self.fullName=f\"{self.table_name}.{self.attribute_name}\"\n",
    "\n",
    "        self.uniquness = self.estUniqueness()\n",
    "        self.cardinality=1\n",
    "        self.value_length = 1/max(1, max([len(x) for x in values]) - 8) #8 is a hyper-parameter which penalties primary key candidates which has a value with length > 8\n",
    "        self.position = 0\n",
    "        self.suffix = self.check_suffix()\n",
    "\n",
    "        self.pkScore = 0\n",
    "        self.pkScore += self.uniquness\n",
    "        self.pkScore += self.cardinality\n",
    "        self.pkScore += self.value_length\n",
    "        self.pkScore += self.position\n",
    "        self.pkScore += self.suffix\n",
    "\n",
    "    def estUniqueness(self):\n",
    "        \"\"\"\n",
    "        Estimate uniqueness of attribute values using HyperLogLog algorithm.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        float\n",
    "            Ratio of unique values to total values\n",
    "        \"\"\"\n",
    "\n",
    "        hll = HyperLogLog()\n",
    "        total = 0\n",
    "        \n",
    "        for value in self.values:\n",
    "            hll.update(str(value).encode('utf8'))\n",
    "            total +=1\n",
    "        \n",
    "        return hll.count() / total\n",
    "    \n",
    "    def check_suffix(self, suffix_list=[\"key\", 'id', 'nr', 'no']):\n",
    "        \"\"\"\n",
    "        Check if attribute name contains common primary key suffixes.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        suffix_list : list of str, optional\n",
    "            List of common primary key suffix strings to check\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            1 if suffix found, 0 otherwise\n",
    "        \"\"\"\n",
    "        for suffix in suffix_list:\n",
    "            if suffix in self.attribute_name:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730b5f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11 \n",
      " CSV files: ['employee_territories.csv', 'products.csv', 'orders.csv', 'customers.csv', 'territories.csv', 'orders_details.csv', 'suppliers.csv', 'employees.csv', 'categories.csv', 'shippers.csv', 'regions.csv']\n",
      "Processing employee_territories.csv: 49 rows, 2 columns\n",
      "Added attribute: employee_territories.employeeid Total Values: 49\n",
      "1.0\n",
      "Added attribute: employee_territories.territoryid Total Values: 49\n",
      "0.5\n",
      "Processing products.csv: 77 rows, 10 columns\n",
      "Added attribute: products.productid Total Values: 77\n",
      "1.0\n",
      "Added attribute: products.productname Total Values: 77\n",
      "0.5\n",
      "Added attribute: products.supplierid Total Values: 77\n",
      "0.3333333333333333\n",
      "Added attribute: products.categoryid Total Values: 77\n",
      "0.25\n",
      "Added attribute: products.quantityperunit Total Values: 77\n",
      "0.2\n",
      "Added attribute: products.unitprice Total Values: 77\n",
      "0.16666666666666666\n",
      "Added attribute: products.unitsinstock Total Values: 77\n",
      "0.14285714285714285\n",
      "Added attribute: products.unitsonorder Total Values: 77\n",
      "0.125\n",
      "Added attribute: products.reorderlevel Total Values: 77\n",
      "0.1111111111111111\n",
      "Added attribute: products.discontinued Total Values: 77\n",
      "0.1\n",
      "Processing orders.csv: 830 rows, 13 columns\n",
      "Added attribute: orders.orderid Total Values: 830\n",
      "1.0\n",
      "Added attribute: orders.customerid Total Values: 830\n",
      "0.5\n",
      "Added attribute: orders.employeeid Total Values: 830\n",
      "0.3333333333333333\n",
      "Added attribute: orders.orderdate Total Values: 830\n",
      "0.25\n",
      "Added attribute: orders.requireddate Total Values: 830\n",
      "0.2\n",
      "Added attribute: orders.shippeddate Total Values: 830\n",
      "0.16666666666666666\n",
      "Added attribute: orders.shipvia Total Values: 830\n",
      "0.14285714285714285\n",
      "Added attribute: orders.freight Total Values: 830\n",
      "0.125\n",
      "Added attribute: orders.shipname Total Values: 830\n",
      "0.1111111111111111\n",
      "Added attribute: orders.shipcity Total Values: 830\n",
      "0.1\n",
      "Added attribute: orders.shipregion Total Values: 830\n",
      "0.09090909090909091\n",
      "Added attribute: orders.shippostalcode Total Values: 830\n",
      "0.08333333333333333\n",
      "Added attribute: orders.shipcountry Total Values: 830\n",
      "0.07692307692307693\n",
      "Processing customers.csv: 91 rows, 10 columns\n",
      "Added attribute: customers.customerid Total Values: 91\n",
      "1.0\n",
      "Added attribute: customers.companyname Total Values: 91\n",
      "0.5\n",
      "Added attribute: customers.contactname Total Values: 91\n",
      "0.3333333333333333\n",
      "Added attribute: customers.contacttitle Total Values: 91\n",
      "0.25\n",
      "Added attribute: customers.city Total Values: 91\n",
      "0.2\n",
      "Added attribute: customers.region Total Values: 91\n",
      "0.16666666666666666\n",
      "Added attribute: customers.postalcode Total Values: 91\n",
      "0.14285714285714285\n",
      "Added attribute: customers.country Total Values: 91\n",
      "0.125\n",
      "Added attribute: customers.phone Total Values: 91\n",
      "0.1111111111111111\n",
      "Added attribute: customers.fax Total Values: 91\n",
      "0.1\n",
      "Processing territories.csv: 53 rows, 3 columns\n",
      "Added attribute: territories.territoryid Total Values: 53\n",
      "1.0\n",
      "Added attribute: territories.territorydescription Total Values: 53\n",
      "0.5\n",
      "Added attribute: territories.regionid Total Values: 53\n",
      "0.3333333333333333\n",
      "Processing orders_details.csv: 2155 rows, 5 columns\n",
      "Added attribute: orders_details.orderid Total Values: 2155\n",
      "1.0\n",
      "Added attribute: orders_details.productid Total Values: 2155\n",
      "0.5\n",
      "Added attribute: orders_details.unitprice Total Values: 2155\n",
      "0.3333333333333333\n",
      "Added attribute: orders_details.quantity Total Values: 2155\n",
      "0.25\n",
      "Added attribute: orders_details.discount Total Values: 2155\n",
      "0.2\n",
      "Processing suppliers.csv: 29 rows, 12 columns\n",
      "Added attribute: suppliers.supplierid Total Values: 29\n",
      "1.0\n",
      "Added attribute: suppliers.companyname Total Values: 29\n",
      "0.5\n",
      "Added attribute: suppliers.contactname Total Values: 29\n",
      "0.3333333333333333\n",
      "Added attribute: suppliers.contacttitle Total Values: 29\n",
      "0.25\n",
      "Added attribute: suppliers.address Total Values: 29\n",
      "0.2\n",
      "Added attribute: suppliers.city Total Values: 29\n",
      "0.16666666666666666\n",
      "Added attribute: suppliers.region Total Values: 29\n",
      "0.14285714285714285\n",
      "Added attribute: suppliers.postalcode Total Values: 29\n",
      "0.125\n",
      "Added attribute: suppliers.country Total Values: 29\n",
      "0.1111111111111111\n",
      "Added attribute: suppliers.phone Total Values: 29\n",
      "0.1\n",
      "Added attribute: suppliers.fax Total Values: 29\n",
      "0.09090909090909091\n",
      "Added attribute: suppliers.homepage Total Values: 29\n",
      "0.08333333333333333\n",
      "Processing employees.csv: 9 rows, 18 columns\n",
      "Added attribute: employees.employeeid Total Values: 9\n",
      "1.0\n",
      "Added attribute: employees.lastname Total Values: 9\n",
      "0.5\n",
      "Added attribute: employees.firstname Total Values: 9\n",
      "0.3333333333333333\n",
      "Added attribute: employees.title Total Values: 9\n",
      "0.25\n",
      "Added attribute: employees.titleofcourtesy Total Values: 9\n",
      "0.2\n",
      "Added attribute: employees.birthdate Total Values: 9\n",
      "0.16666666666666666\n",
      "Added attribute: employees.hiredate Total Values: 9\n",
      "0.14285714285714285\n",
      "Added attribute: employees.address Total Values: 9\n",
      "0.125\n",
      "Added attribute: employees.city Total Values: 9\n",
      "0.1111111111111111\n",
      "Added attribute: employees.region Total Values: 9\n",
      "0.1\n",
      "Added attribute: employees.postalcode Total Values: 9\n",
      "0.09090909090909091\n",
      "Added attribute: employees.country Total Values: 9\n",
      "0.08333333333333333\n",
      "Added attribute: employees.homephone Total Values: 9\n",
      "0.07692307692307693\n",
      "Added attribute: employees.extension Total Values: 9\n",
      "0.07142857142857142\n",
      "Added attribute: employees.photo Total Values: 9\n",
      "0.06666666666666667\n",
      "Added attribute: employees.notes Total Values: 9\n",
      "0.0625\n",
      "Added attribute: employees.reportsto Total Values: 9\n",
      "0.058823529411764705\n",
      "Added attribute: employees.photopath Total Values: 9\n",
      "0.05555555555555555\n",
      "Processing categories.csv: 8 rows, 4 columns\n",
      "Added attribute: categories.categoryid Total Values: 8\n",
      "1.0\n",
      "Added attribute: categories.categoryname Total Values: 8\n",
      "0.5\n",
      "Added attribute: categories.description Total Values: 8\n",
      "0.3333333333333333\n",
      "Added attribute: categories.picture Total Values: 8\n",
      "0.25\n",
      "Processing shippers.csv: 6 rows, 3 columns\n",
      "Added attribute: shippers.shipperid Total Values: 6\n",
      "1.0\n",
      "Added attribute: shippers.companyname Total Values: 6\n",
      "0.5\n",
      "Added attribute: shippers.phone Total Values: 6\n",
      "0.3333333333333333\n",
      "Processing regions.csv: 4 rows, 2 columns\n",
      "Added attribute: regions.regionid Total Values: 4\n",
      "1.0\n",
      "Added attribute: regions.regiondescription Total Values: 4\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "def load_csv_files(directory_path):\n",
    "    \"\"\"\n",
    "    Load CSV files from a directory and create Attribute objects.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    directory_path : str\n",
    "        Path to directory containing CSV files\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary mapping \"table.column\" strings to Attribute objects\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    Prints progress information during loading\n",
    "    \"\"\"\n",
    "    attributes = {}\n",
    "\n",
    "    csv_files = [f for f in os.listdir(directory_path)]\n",
    "\n",
    "    print(f\"Found {len(csv_files)} \\n CSV files: {csv_files}\")    \n",
    "\n",
    "    for filename in csv_files:\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        table_name = os.path.splitext(filename)[0]\n",
    "\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Processing {filename}: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "\n",
    "        for i, column in enumerate(df.columns):\n",
    "            non_null_values = df[column].astype(str).dropna().tolist()\n",
    "            if non_null_values:\n",
    "                attr = Attribute(table_name, column, non_null_values)\n",
    "                attr.position = 1/(i+1)\n",
    "                attributes[f\"{table_name}.{column}\"] = attr\n",
    "                print(f\"Added attribute: {attr.table_name}.{attr.attribute_name} Total Values: {len(attr.values)}\")\n",
    "                \n",
    "    return attributes\n",
    "    \n",
    "attributes = load_csv_files(\"/home/haseeb/Desktop/EKAI/ERD_automation/Dataset/train/northwind-db\")            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e8595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractPrimaryKeys(attributes):\n",
    "    \"\"\"\n",
    "    Extract primary keys from attributes based on their pkScore.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    attributes : dict\n",
    "        Dictionary mapping \"table.column\" strings to Attribute objects\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary mapping table names to tuples of (column name, pkScore)\n",
    "    \"\"\"\n",
    "    pk_table = {}  # {table name: (column name, score)}\n",
    "\n",
    "    for key, value in attributes.items():\n",
    "        table_name = key.split(\".\")[0]\n",
    "        current_pk = pk_table.get(table_name)\n",
    "        if not current_pk or current_pk[1] < value.pkScore:\n",
    "            pk_table[table_name] = (value.fullName, value.pkScore)\n",
    "    return pk_table\n",
    "\n",
    "pk_table = extractPrimaryKeys(attributes=attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c455553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(inds)=111\n"
     ]
    }
   ],
   "source": [
    "def read_IND(file_path):\n",
    "    \"\"\"\n",
    "    Read inclusion dependencies from a file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str\n",
    "        Path to file containing inclusion dependencies\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    list of IND\n",
    "        List of inclusion dependency objects\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    File format should be one dependency per line as: dependent=reference\n",
    "    \"\"\"\n",
    "    inds = []\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            vars = line.strip().split(\"=\")\n",
    "            inds.append(IND(attributes[vars[0]], attributes[vars[1]]))\n",
    "    return inds\n",
    "inds = read_IND(\"/home/haseeb/Desktop/EKAI/ERD_automation/codes/inclusionDependencyWithSpider/spider_results/northwind.txt\")\n",
    "print(f\"{len(inds)=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea7c88b",
   "metadata": {},
   "source": [
    "# FK candidate prerfiltering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f8bc214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n"
     ]
    }
   ],
   "source": [
    "def prefiltering(inds):\n",
    "    \"\"\"\n",
    "    Filter inclusion dependencies based on primary key and null value criteria.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    inds : list of IND\n",
    "        List of inclusion dependency objects to filter\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    list of IND\n",
    "        Filtered list of inclusion dependencies that meet criteria:\n",
    "        - Reference attribute is a primary key\n",
    "        - Neither dependent nor reference is all null values\n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    Uses global pk_table dictionary for primary key lookup\n",
    "    \"\"\"\n",
    "    pruned_inds = []\n",
    "    for ind in inds:\n",
    "        #Checking if reference variable is a primary key\n",
    "        is_pk = False\n",
    "        for table_name, pk in pk_table.items():\n",
    "            if pk[0].split(\".\")[1] == ind.reference.attribute_name:\n",
    "                is_pk=True\n",
    "                break\n",
    "\n",
    "        #Checking if either all of the dependent or reference attribute is null\n",
    "        dependent_all_null = True\n",
    "        reference_all_null = True\n",
    "        for value in ind.reference.values:\n",
    "            if value != \"nan\":\n",
    "                reference_all_null = False\n",
    "        for value in ind.dependent.values:\n",
    "            if value !=\"nan\":\n",
    "                dependent_all_null = False\n",
    "        \n",
    "        if is_pk and (not reference_all_null) and (not dependent_all_null):\n",
    "            pruned_inds.append(ind)\n",
    "\n",
    "    return pruned_inds\n",
    "\n",
    "inds = prefiltering(inds=inds)\n",
    "print(len(inds))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ERD_automation_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
